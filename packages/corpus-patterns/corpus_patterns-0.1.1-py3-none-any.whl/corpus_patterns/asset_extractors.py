from collections.abc import Iterator
from pathlib import Path
from typing import Any

import srsly  # type: ignore
from sqlite_utils import Database

from .utils import extract_lines_from_txt_files


def extract_concept_txts(path: Path) -> Iterator[dict[str, str]]:
    for txt_file in path.glob("**/q.txt"):
        for line in txt_file.read_text().splitlines():
            if line.strip():
                yield {
                    "label": "concept",
                    "pattern": line,
                    "id": f"{txt_file.parent.parent.stem}/{txt_file.parent.stem}",
                }


def extract_concept_jsonl(path: Path) -> Iterator[dict[str, str | list[dict[str, Any]]]]:
    for json_file in path.glob("**/patterns.json"):
        matchers = srsly.read_json(json_file)
        if matchers and isinstance(matchers, list):
            for matcher_pattern in matchers:
                yield {
                    "label": "concept",
                    "pattern": matcher_pattern,
                    "id": f"{json_file.parent.parent.stem}/{json_file.parent.stem}",
                }


def validated_path(f: str) -> Path:
    patterns_path = Path(f)  # type: ignore
    if not patterns_path.exists():
        raise Exception(f"Invalid {f=}")
    return patterns_path


def create_concept_patterns(path: str | Path) -> list[dict[str, Any]]:
    """Based on the `q.txt` and `patterns.json` files found in the path, generate
    patterns in a list of dicts where each dict consists of the following keys:

    1. `id`: <grandparent-folder>/<parent-folder>
    2. `label`: "concept"
    3. `pattern`: either a string or a list of dicts, following the spacy Matcher pattern
    style.
    """
    if isinstance(path, str):
        path = validated_path(path)
    return list(extract_concept_jsonl(path)) + list(extract_concept_txts(path))


def filter_unique_texts(input_dicts):
    unique_texts = set()
    result_dicts = []

    for d in input_dicts:
        text = d["text"]
        if text not in unique_texts:
            unique_texts.add(text)
            result_dicts.append(d)
    return result_dicts


def create_fts_expr(p: Path) -> str:
    files = p.glob("**/q.txt")
    lines = extract_lines_from_txt_files(files)
    quoted = [f'"{q}"' for q in lines]
    return " OR ".join(quoted)


def extract_txt_from_db(
    source_db_file: str,
    path: Path,
    max_segments: int,
    min_char_segment: int = 100,
    max_char_segment: int = 3000,
    is_unique_txt: bool = True,
):
    """An fts expression is auto-generated by `q.txt` files found in the `path`. This
    expression is used to generate strings of text that match the aggregated query."""
    db = Database(source_db_file)
    tbl = db["opinion_segments"]
    rows = tbl.search(  # type: ignore
        q=create_fts_expr(path),
        where="category='ruling' and char_count > :min_char and char_count < :max_char ",
        where_args={"min_char": min_char_segment, "max_char": max_char_segment},
        limit=max_segments,
        columns=["text", "id"],
    )
    if is_unique_txt:
        rows = filter_unique_texts(rows)
    return rows
