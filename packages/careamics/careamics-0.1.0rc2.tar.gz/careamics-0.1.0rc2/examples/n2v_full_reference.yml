---
# Name, composed of letters, numbers, spaces, dashes and underscores
experiment_name: project_name

# Working directory (logs, models, etc), its parent folder must exist
working_directory: path/to/working_directory

# Optional
# Absolute or relative (wrt working_directory) path to model
trained_model: best_model.pth

algorithm:
  # Loss, currently only n2v is supported
    loss: n2v

  # Model, currently only UNet is supported
    model: UNet

  # Dimensions 2D (False) or 3D (True)
    is_3D: false

  # Optional, masking strategy, currently only default is supported
    masking_strategy: default
  # Optional, percentage of masked pixel per patch (between 0.1 and 20%)
    masked_pixel_percentage: 0.2
  # Optional, parameters of the model
    model_parameters:
    # Depth betwen 1 and 10
        depth: 2
    # Number of filters of the first level, must be divisible by 2
        num_filter_base: 32

training:
  # Number of epochs, greater or equal than 1
    num_epochs: 100

  # Patch size, 2D or 3D, divisible by 2
    patch_size: [64, 64]

  # Batch size, greater or equal than 1
    batch_size: 128

  # Optimizer
    optimizer:
    # Name, one of Adam or SGD
        name: Adam

    # Optional, parameters of the optimizer
    # see https://pytorch.org/docs/stable/optim.html#algorithms
        parameters:
            lr: 0.0004

  # Learning rate scheduler
    lr_scheduler:
    # Name, one of ReduceLROnPlateau or StepLR
        name: ReduceLROnPlateau
    # Optional, parameters of the learning rate scheduler
    # see https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
        parameters:
            mode: min
            patience: 10
            factor: 0.5

  # Use augmentation (True or False)
    augmentation: true

  # Optional, use WandB (True or False), must be installed in your conda environment
    use_wandb: false

  # Optional, number of workers for data loading, greater or equal than 0
    num_workers: 0

  # Optional, automatic mixed precision
    amp:
    # Use (True or False)
        use: true
    # Optional, scaling parameter for mixed precision training, power of 2 recommended.
    # minimum is 512, maximum is 65536
        init_scale: 1024

  # Torch.compile (True or False)
    compile:
        use: false

data:
  # Controls the type of dataloader to use. Set to False if data won't fit into memory
    in_memory: false

  # Extension of the data, e.g. tiff or zarr
    data_format: tiff

  # Axes, among STCZYX with constraints on order
    axes: SYX
