---
# Name, composed of letters, numbers, spaces, dashes and underscores
experiment_name: N2V_SEM

# Working directory (logs, models, etc), its parent folder must exist
working_directory: n2v_sem

algorithm:
  # Loss, currently only n2v is supported
    loss: n2v

  # Model, currently only UNet is supported
    model: UNet

  # Dimensions 2D (False) or 3D (True)
    is_3D: false

training:
  # Number of epochs, greater or equal than 1
    num_epochs: 100

  # Patch size, 2D or 3D, divisible by 2
    patch_size: [64, 64]

  # Batch size, greater or equal than 1
    batch_size: 128

  # Optimizer
    optimizer:
    # Name, one of Adam or SGD
        name: Adam
    # Optional, parameters of the optimizer
    # see https://pytorch.org/docs/stable/optim.html#algorithms
        parameters:
            lr: 0.0004

  # Learning rate scheduler
    lr_scheduler:
    # Name, one of ReduceLROnPlateau or StepLR
        name: ReduceLROnPlateau
    # Optional, parameters of the learning rate scheduler
    # see https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
        parameters:
            factor: 0.5

  # Use augmentation (True or False)
    augmentation: true

  # Optional, use WandB (True or False), must be installed in your conda environment
    use_wandb: false

  # Optional, number of workers for data loading, greater or equal than 0
    num_workers: 4

data:
  # Controls the type of dataloader to use. Set to False if data won't fit into memory
    in_memory: true

  # Extension of the data, one of npy, tiff and tif
    data_format: tif

  # Axes, among STCZYX with constraints on order
    axes: YX
