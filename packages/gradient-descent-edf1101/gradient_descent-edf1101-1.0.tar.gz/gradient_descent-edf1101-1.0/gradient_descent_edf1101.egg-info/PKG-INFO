Metadata-Version: 2.1
Name: gradient-descent-edf1101
Version: 1.0
Summary: Gradient Descent module
Home-page: https://github.com/edf1101/GradientDescent
Author: Ed Fillingham
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE

# Gradient Descent Module
## Introduction
 _Gradient Descent for the Fundamentals of Machine Learning module of my Computer Science Degree_

## Getting Started

### Installation
This can be installed via pip by running

```pip install ```

It can then be used as a regular module

### Examples
Examples found in the examples folder both as a python file and as jupyter notebooks

![Example](https://github.com/edf1101/GradientDescent/assets/96292907/b8157a76-769f-4313-ad71-fcc6e20e574b)

- The blue points are the random points that somewhat fit the curve 2x<sup>2</sup> - 3x + 4
- The Red line is the actual curve
- The Green line is the predicted curve

## Prerequisites
Modules Used
- Matplotlib

Version of python Used = 3.11.4


## Developer Details
### Documentation
HTML file documentation generated by sphinx can be found [here](docs/_build/html/index.html)
### Linting
In the base of the project you can run ```pylint gradient_descent``` 
### Learning Parameters (for OK results)
- Quartic - learning = 0.0000000003
- Cubic - learning = 0.00000003
- Quadratic - learning = 0.000001
- Linear - learning = 0.00001

In general for each extra polynomial term you add it should be ~100x smaller.
Smaller learning rates may get better results, but you will need to have more attempts to reach it since it learns slower

### Testing
pytest is required for these tests.
This can be installed by ```pip install pytest```

## Details
### License
This falls under the MIT license found [here](LICENSE)
### Authors
Ed Fillingham
### Sources
This project can be found at https://github.com/edf1101/GradientDescent
