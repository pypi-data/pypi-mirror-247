Metadata-Version: 2.1
Name: kafka-slurm-agent
Version: 1.1.3
Summary: The Kafka Slurm Agent is a tool for submitting computing tasks to the Slurm queues on multiple clusters. It uses Kafka to asynchronously communicate with an agent installed on the cluster.It contains a monitoring tool and a job submitter.
Home-page: https://github.com/prubach/kafka-slurm-agent
Author: PaweÅ‚ Rubach
Author-email: pawel.rubach@gmail.com
License: UNKNOWN
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: faust-streaming
Requires-Dist: kafka-python
Requires-Dist: psutil >=5.6.6
Requires-Dist: python-math
Requires-Dist: simple-slurm
Requires-Dist: werkzeug
Requires-Dist: wrapt-timeout-decorator

# Kafka Slurm Agent

The Kafka Slurm Agent is a tool for submitting computing tasks to the Slurm queues on multiple clusters. 
It uses Kafka to asynchronously communicate with an agent installed on each cluster. 
It contains a monitoring tool and a job submitter.

## Installation.

Use the standard ``pip`` tool to install. The recommended way is to use a Python virtual environment:
``python3 -m venv venv``
``source venv/bin/activate``
``pip install kafka-slurm-agent``

## Using

In the folder in which you created the ``venv`` subfolder run the following command:
``kafka-slurm create .``
This will generate a configuration file ``kafkaslurm_cfg.py``, startup scripts and a module (``my_monitor_agent.py``) 
for adding your own implementation of the monitoring agent. This implementation may react to the incoming events
with computed jobs and handle them.


Test connectivity
#docker run --add-host zalman:172.17.0.1 -p 8088:8080 -e KAFKA_CLUSTERS_0_NAME=local -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=172.17.0.1:9092 -d provectuslabs/kafka-ui:latest


